{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd     \n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), 'teethes')\n",
    "\n",
    "dataset_train_dir = os.path.join(dataset_dir, 'train')\n",
    "dataset_validation_dir = os.path.join(dataset_dir, 'validation')\n",
    "features_dir = os.path.join(dataset_dir, 'features')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando classe extratora de features\n",
    "A classe FeatureExtractor irá utilizar um modelo pronto disponibilizado pelo TensorFlow. Tem-se a arquitetura VGG-16 que é um rede neural convulacional que possui 16 camadas.\n",
    "Mais informações sobre a arquitetura VGG-16 ver em: [VGG-16 Architecture](https://datagen.tech/guides/computer-vision/vgg16/)\n",
    "\n",
    "## Sobre o modelo\n",
    "- O modelo deve receber como entrada imagens de tamanho 224x224\n",
    "- Como ponderação o modelo utiliza o peso imagenet, amplamente utilizado em modelos para classificação de imagens\n",
    "- No FeatureExtractor estamos coletando a saída da camada FC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        base_model = VGG16(weights='imagenet')\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "    \n",
    "    def extract(self, img):\n",
    "        img = img.resize((224, 224))\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "        image_array = image.img_to_array(img)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        image_array = preprocess_input(image_array)\n",
    "        \n",
    "        feature = self.model.predict(image_array)[0]\n",
    "\n",
    "        return feature / np.linalg.norm(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando uma imagem com modificações randomizadas\n",
    "A necessidade de gerar uma imagem com algumas modificações surgiu da possibilidade de ser colocado uma imagem nova no database com alguma modificação, como zoom, flip horizontal entre outras, para contornar esse problema decide-se criar uma augmented dataset que além das imagens originais, também possui as imagens originais modificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyRandomizedModificationInImages(original_image):\n",
    "    temp_dir = os.path.join(dataset_dir, 'temp')\n",
    "    \n",
    "    data_generator = ImageDataGenerator(\n",
    "        zoom_range=[0.8, 1.2], \n",
    "        horizontal_flip=True,  \n",
    "        rotation_range=30  \n",
    "    )\n",
    "    \n",
    "    expanded_image = tf.expand_dims(original_image, axis=0)\n",
    "    \n",
    "    modified_image = data_generator.flow(expanded_image, batch_size=1)[0][0]\n",
    "    modified_image = Image.fromarray(modified_image.astype('uint8'), 'RGB')\n",
    "    modified_image.save(os.path.join(temp_dir, f'{original_image.filename}_augmented.png'))\n",
    "    \n",
    "    modified_image_path = os.path.join(temp_dir, f'{original_image.filename}_augmented.png')\n",
    "    \n",
    "    return modified_image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtendo as features das imagens no datasete de treino\n",
    "Para obter as features das imagens, itera-se sobre cada uma delas existente no dataset de treinamento chamando a função extract() da instância do feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_images_dir = os.path.join(dataset_train_dir, 'images')\n",
    "\n",
    "dataset_train_file_images = os.listdir(dataset_train_images_dir)\n",
    "\n",
    "for image_name in tqdm(dataset_train_file_images):\n",
    "    feature = feature_extractor.extract(img=Image.open(os.path.join(dataset_train_images_dir, str(image_name))))\n",
    "    \n",
    "    feature_path = os.path.join(features_dir, '{}.npy'.format(str(image_name).replace('.png','')))\n",
    "    np.save(feature_path, feature)\n",
    "\n",
    "    augmented_image_path = applyRandomizedModificationInImages(Image.open(os.path.join(dataset_train_images_dir, str(image_name))))\n",
    "    augmented_feature = feature_extractor.extract(img=Image.open(augmented_image_path))\n",
    "    augmented_feature_path = os.path.join(features_dir, '{}_augmented.npy'.format(str(image_name).replace('.png','')))\n",
    "    np.save(augmented_feature_path, augmented_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colocando as features em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa911451f1da4d79b8df00ee2f5c7d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = []\n",
    "for file_name in tqdm(os.listdir(features_dir)):\n",
    "  add_feature = np.load(os.path.join(features_dir, str(file_name)))\n",
    "  add_feature = pd.DataFrame([add_feature])\n",
    "  \n",
    "  add_feature['image'] = file_name.replace('.npy','.png')\n",
    "\n",
    "  features.append(add_feature)\n",
    "\n",
    "features = pd.concat(features, axis=0)\n",
    "features.to_csv(os.path.join(dataset_dir, 'feature_extraction.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo as features já salvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_features = pd.read_csv(os.path.join(dataset_dir, 'feature_extraction.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando a semelhança da imagem com o dataset disponível\n",
    "1. Cópia do conteúdo existente no DataFrame loaded_features\n",
    "2. Remoção da coluna image(que possui o nome do arquivo da imagem) do DataFrame, já que ela não possui informação relevante para o conteúdo das imagens\n",
    "3. Obtenção apenas dos valores das features\n",
    "4. Cálculo da distância euclidiana(responsável em indicar a similiridade entre duas imagens) entre as features das imagens do dataset de treino com as features da imagem fornecida como entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_similarity(image_name):\n",
    "    dataset_manual_tests = os.path.join(dataset_dir, 'manual_tests')\n",
    "\n",
    "    image_to_compare = Image.open(os.path.join(dataset_manual_tests, image_name))\n",
    "    image_to_compare_features = feature_extractor.extract(image_to_compare)\n",
    "\n",
    "    features_data = loaded_features.copy()\n",
    "    features_data = features_data.drop(columns = ['image'])\n",
    "    features_data = features_data.values\n",
    "\n",
    "    euclidean_distance = np.linalg.norm(features_data - image_to_compare_features, axis=1)\n",
    "\n",
    "    lower_distance_images_quantity = 30\n",
    "    images_with_lowest_distance_ids = np.argsort(euclidean_distance)[:lower_distance_images_quantity]\n",
    "\n",
    "    # Get only the lines with the images that have the given id\n",
    "    more_similar_images = loaded_features.iloc[images_with_lowest_distance_ids,:]['image']\n",
    "    scores = pd.DataFrame({\n",
    "        'image': more_similar_images,\n",
    "        'score': euclidean_distance[images_with_lowest_distance_ids]}\n",
    "    )\n",
    "    images_and_scores = scores.reset_index(drop=True)\n",
    "\n",
    "    return images_and_scores, image_to_compare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando as imagens semelhantes a passada pela entrada\n",
    "Para verificar se uma imagem é semelhante a outra deve-se definir qual nível de semelhança deve ser considerado para classifica-la como \"iguais\". Como na aplicação atual busca-se imagens repetidas, normalmente a distância euclidiana deve ser bem baixa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_similarity(image1, image2, similarity_score):\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "  ax1.imshow(image1)\n",
    "  ax1.set_title('Imagem to compare: ' + os.path.basename(image1.filename))\n",
    "  ax1.axis('off')\n",
    "\n",
    "  ax2.imshow(image2)\n",
    "  ax2.set_title('Imagem in dataset: ' + os.path.basename(image2.filename))\n",
    "  ax2.axis('off')\n",
    "\n",
    "  fig.text(0.5, 0.05, 'Similaridade: {:.2f}%'.format(100 - similarity_score), ha='center', fontsize=12)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes manuais feitos\n",
    "1. Imagem com inversão horizontal\n",
    "2. Imagem com inversão vertical\n",
    "3. Imagem com rotação de 90 graus para a direita\n",
    "4. Imagem com zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n"
     ]
    }
   ],
   "source": [
    "## 1\n",
    "# images_and_scores, image_to_compare = verify_similarity('2001_horizontal_revert.png')\n",
    "## 2\n",
    "# images_and_scores, image_to_compare = verify_similarity('2001_vertical_revert.png')\n",
    "## 3\n",
    "# images_and_scores, image_to_compare = verify_similarity('2001_90_rotation.png')\n",
    "## 4\n",
    "images_and_scores, image_to_compare = verify_similarity('2001_zoomed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_euclidean_distance_to_be_equal = 0.3\n",
    "\n",
    "images_and_scores = images_and_scores.sort_values(by=['score'])\n",
    "\n",
    "for i in range(len(images_and_scores)):\n",
    "    score = images_and_scores['score'][i]\n",
    "    if score < minimum_euclidean_distance_to_be_equal:\n",
    "        plot_images_with_similarity(image_to_compare, Image.open(os.path.join(dataset_train_dir, 'images', images_and_scores['image'][i]).replace('.jpg','')), score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
